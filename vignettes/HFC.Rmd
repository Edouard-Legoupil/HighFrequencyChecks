---
title: "High Frequency Checks: a template for data quality monitoring"
author: "Yannick Pascaud"
date: "`r format(Sys.time(), '%d %B, %Y')`"
always_allow_html: yes
header-includes:
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
output: rmarkdown::html_vignette
vignette: >
  \usepackage[utf8]{inputenc}
  %\VignetteIndexEntry{High Frequency Checks: a template for data quality monitoring}
  %\VignetteEngine{knitr::rmarkdown}
geometry: margin=0.5in
fontsize: 10pt
editor_options: 
  chunk_output_type: inline
---

Supervising the quality of data collection is not straightforward. Survey questionnaires are often quite long and have systematic control is worth automatising.

The HighFrequencyCheck package is a translation in in R of the [Stata package from Innovations for Poverty Action](https://github.com/PovertyAction/high-frequency-checks). It brings a series of convenience functions to monitor data quality during the data collection when running a survey with kobotoolbox (or any `xlsform` compatible platform). 

Those can be performed periodically during the data collection process to check for possible errors and provide meaningful inputs to the enumerators. All these functions do not have to be ran at the same period of time. They are provided there to help data supervisor to build reports:

* A wrapper function is included to generate directly an final data quality assessment Rmd Report

* A shyniApp Interface is also included to provide a live monitoring dashbaord

## Measuring data collection quality 

Data collection quality monitoring includes 4 different dimensions

 1. Correct set-up of data collection devices
 2. Data collected according the samplin plan
 3. Enumerator rigorous work standards 
 4. Enumerator productivity 

Ideally the data collection monitoring dashboard should be known to all enumerators so that they are aware of the data quality metrics that will be used to assess the quality of their work and potentially some incentive can be offered for the enumerators performing on the quality metrics (_It is good to recall that each records in household survey cost between 15 to 50 USD_). Some of those indicators can support some remedial supervision interventions, such as calling individually the enumerator and point some specific issues that were detected.

Below are the required configuration and an illustration of those indicators based on a demo dataset included in the package.

## Initial configuration

### loading the required R packages

```{r message=FALSE, warning=FALSE, include=TRUE, echo = TRUE}
library(knitr)
library(gsubfn)
library(tidyverse)
library(data.table)
library(HighFrequencyChecks)
library(kableExtra)
library(ggplot2)
```

### Loading survey dataset (microdata)

In a production environment, it is possible to connect this a live API (kobotoolbox, ODK , etc.)

```{r, include=TRUE}
sample_dataset <- HighFrequencyChecks::sample_dataset
# correction for uppercase/lowercase in the site name (should not happen if we can use the same name in the shapefile/kobo/sample size)
sample_dataset$union_name <- tolower(sample_dataset$union_name)
```

### Loading sampling plan

The sampling plan is defined through the sampling strategy. It includes for each enumerator the sufficient details for the enumerator to reach out to respondent satisfying the sampling target definition (i.e. name, location, phone number)

```{r, include=TRUE}
SampleSize <- HighFrequencyChecks::SampleSize
# correction for uppercase/lowercase in the site name (should not happen if we can use the same name in the shapefile/kobo/sample size)
SampleSize$Union <- tolower(SampleSize$Union)
```

### Loading geodata for the surveyed area

Often sampling strategy includes a geographic coverage.

This can be overview through either:

 * a defined polygon, aka area or admin unit


```{r message=FALSE, warning=FALSE, include=TRUE}
adm <- HighFrequencyChecks::admin
# To avoid futher issue the unique key with the survey dataset is chnaged to all small cap 
adm$Union <- tolower(adm$Union)
```

 * a sampling point, around which enumerators are supposed to randomly interview persons.

```{r, include=TRUE}
pts <- HighFrequencyChecks::SamplePts
```

### Specific variables to be controlled

Below are initialized variables to perform data quality control for this specific dataset

#### geodata



 * Name of variables for geographic coordinates as recorded by data collection device GPS

```{r, include=TRUE}
df_coord <- c("X_gps_reading_longitude","X_gps_reading_latitude")
```

 * Name of location (__matching external geodata__)

```{r eval=TRUE, echo=TRUE, results='asis'}
df_site <- "union_name"
```


 * Name of unique key in polygon file

```{r, include=TRUE}
admin_site <- "Union"
```


#### Variable of interest for data quality check

 *  Variable recording initial consent

```{r, include=TRUE}
consent <- "survey_consent"
```


 * Variable recording multiples screening questions

```{r, include=TRUE}
questions <- c("consent_received.shelter_nfi.non_food_items[.]",
             "consent_received.food_security.main_income[.]",
             "consent_received.child_protection.boy_risk[.]",
             "consent_received.child_protection.girl_risk[.]")
```


 * Variable to be checked

```{r, include=TRUE}
reportcol <- c("enumerator_id","X_uuid")
```

### Metadata

 * unique ID for each record

```{r, include=TRUE}
uuid <- "X_uuid"
```

 * dates

```{r, include=TRUE}
dates <- c("survey_start","end_survey")
 
## Official date for start of data collection
startdate <- "11/11/2018"

surveydte <- "survey_date"

```


* Variable used to record enumerator identifiers

```{r, include=TRUE}
enumid <- "enumerator_id"
```


#### Qualiity target


 * What is the minimum survey duration in minutes (when using all skip logic)?

```{r, include=TRUE}
mindur <- 10
```

 * minans answers per specific questions

```{r, include=TRUE}
minans <- 3
```

* Standard value

```{r, include=TRUE}
sdvalue <- 2
```


 * Size of the buffer in meters around the assigned data collection location points

```{r, include=TRUE}
buffer <- 10
```

### Server specific config

```{r, include=TRUE}
otherpattern <- "_other$"

dteformat <- "%m/%d/%Y"
```

## 1. Correct set-up of data collection devices

### Duplicates in unique ID

```{r eval=TRUE, echo=TRUE, results='asis'}
list[dts,err] <- chk2b_unique_id(sample_dataset, 
                                 uuid, 
                                 consent, 
                                 reportcol, 
                                 TRUE)
sample_dataset <- dts

#kable(head(err,10))
knitr::kable(err, 
             caption = "Detected records with errors") %>%
           kable_styling(bootstrap_options = c("striped", "bordered",
                                               "condensed", "responsive"),
                         font_size = 9)

```

### Configuration of dates on device

 * Checking record for which interview that do not end on the same day as they started

```{r eval=TRUE, echo=TRUE, results='asis'}
list[dts,err] <- chk3a_date_mistake(sample_dataset, 
                                    consent, 
                                    dates, 
                                    reportcol, 
                                    FALSE)
# sample_dataset<-dts

if(nrow(err)>0){
  #kable(head(err,10))
knitr::kable(err, 
             caption = "Detected records with errors") %>%
           kable_styling(bootstrap_options = c("striped", "bordered",
                                               "condensed", "responsive"),
                         font_size = 9)
} else {
  cat("__No errors__: All interviews ended on the same day as they started")
}
```

 * Checking record for which interview ended before they start

```{r eval=TRUE, echo=TRUE, results='asis'}
list[dts,err] <- chk3b_date_mistake(sample_dataset, 
                                    consent, 
                                    dates, 
                                    reportcol, 
                                    FALSE)
# sample_dataset<-dts

if(nrow(err)>0){
  #kable(head(err,10))
knitr::kable(err, 
             caption = "Detected records with errors") %>%
           kable_styling(bootstrap_options = c("striped", "bordered",
                                               "condensed", "responsive"),
                         font_size = 9)
} else {
  cat("__No errors__: all interview ended before they start")
}
```



 * Checking record for which interview tagged in the future

```{r eval=TRUE, echo=TRUE, results='asis'}
list[dts,err] <- chk3d_date_mistake(sample_dataset, 
                                    consent, 
                                    dates, 
                                    reportcol, 
                                    FALSE)
# sample_dataset <- dts
if(nrow(err)>0){
  #kable(head(err,10))
knitr::kable(err, 
             caption = "Detected records with errors") %>%
           kable_styling(bootstrap_options = c("striped", "bordered",
                                               "condensed", "responsive"),
                         font_size = 9)
} else {
  cat("__No errors__: records dat are not in the future")
}
```


## 2. Data collected according the plan



### Interviews made before the first day of data collection

```{r eval=TRUE, echo=TRUE, results='asis'}
list[dts,err] <- chk3c_date_mistake(sample_dataset, 
                                    dates,consent,  
                                    startdate, 
                                    reportcol, 
                                    FALSE)

# sample_dataset <- dts
if(nrow(err)>0){
  #kable(head(err,10))
knitr::kable(err, 
             caption = "Detected records with errors") %>%
           kable_styling(bootstrap_options = c("striped", "bordered",
                                               "condensed", "responsive"),
                         font_size = 9)
} else {
  cat(paste0("__No errors__: all records occured after the official beginning of data collection on ", startdate))
}
```

### Recorded site name for each interview matches the name of the location

```{r eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}
list[dts,err] <- chk1di_GIS_site(adm, 
                                 sample_dataset, 
                                 df_site, 
                                 df_coord, 
                                 admin_site, 
                                 consent, 
                                 reportcol, 
                                 TRUE)
sample_dataset <- dts

#kable(head(err,10))
knitr::kable(err, 
             caption = "Detected records with errors") %>%
           kable_styling(bootstrap_options = c("striped", "bordered",
                                               "condensed", "responsive"),
                         font_size = 9)
```

### Recorded locations for each interview within a **`r buffer`** meter buffer from a sample point

```{r eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}
list[dts,err] <- chk1dii_GIS_Xm(sample_dataset, 
                                pts, 
                                df_coord, 
                                buffer, 
                                consent, 
                                reportcol, 
                                TRUE)
sample_dataset <- dts

#kable(head(err,10))
knitr::kable(err, 
             caption = "Detected records with errors") %>%
           kable_styling(bootstrap_options = c("striped", "bordered",
                                               "condensed", "responsive"),
                         font_size = 9)
```
### Tracking sheet per site

```{r eval=TRUE, echo=TRUE, results='asis'}
sf_site="Union"
sf_target="SS"
sf_nbpts="TotPts"
formul=c("done-no-not_eligible-deleted","done-no-not_eligible-deleted-SS")
colorder=c("site","SS","TotPts","done","not_eligible","no","deleted","yes","final","variance")

reportlog <- chk7bii_tracking(sample_dataset, 
                              SampleSize, 
                              df_site, 
                              sf_site, 
                              consent, 
                              sf_target, 
                              sf_nbpts, 
                              formul, 
                              colorder)
kable(head(reportlog,10))
```

## 4. Enumerators rigorous work standards

### Durations of Interviews

Beware that Interviews with potential errors on the dates are not marked for deletion which can lead to weird duration

```{r eval=TRUE, echo=TRUE, results='asis'}
list[avg,tot] <- chk5a_duration(sample_dataset, 
                                dates)
# sample_dataset <- dts
cat("The total time of data collection is ", tot, " minutes and the average time per survey is ", avg, " minutes")
```


### Enumerators who made a survey below **`r mindur`** minutes

```{r eval=TRUE, echo=TRUE, results='asis'}
list[dts,err] <- chk5b_duration_Xmin(sample_dataset, 
                                     consent, 
                                     dates, 
                                     reportcol, 
                                     mindur, 
                                     TRUE)
sample_dataset <- dts
#kable(head(err,10))
knitr::kable(err, 
             caption = "Detected records with errors") %>%
           kable_styling(bootstrap_options = c("striped", "bordered",
                                               "condensed", "responsive"),
                         font_size = 9)
```

### Enumerators who pick up less than **`r minans`** answers per specific questions

```{r eval=TRUE, echo=TRUE, results='asis'}
reportlog <- chk6g_question_less_X_answers(sample_dataset, 
                                           enumid, 
                                           questions, 
                                           minans)
kable(head(reportlog,10))
```



### Number of other distinct values (for the questions with a possibility of other)

```{r eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}
reportlog <- chk4biv_others_values(sample_dataset, 
                                   otherpattern, 
                                   enumid, 
                                   TRUE)
kable(head(reportlog,10))
```


## 5. Enumerator productivity

### How many completed interview per day fro the project?

```{r eval=TRUE, echo=TRUE, results='asis'}
reportlog <- chk7ai_productivity(sample_dataset, 
                                 surveydte, 
                                 dteformat, 
                                 consent)
kable(head(reportlog,10))
```


### How many attempted interview per day and obtained consent?

```{r eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}
reportlog <- chk7bi_nb_status(sample_dataset, 
                              surveydte, 
                              dteformat, 
                              consent)
kable(head(reportlog,10))
```

### Percentage of survey per consent status by enumerator

```{r eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}
reportlog <- chk6a_refusal(sample_dataset, 
                           consent, 
                           enumid)
kable(head(reportlog,10))
```

### Average interview duration by enumerator

```{r eval=TRUE, echo=TRUE, results='asis'}
reportlog <- chk6b_duration(sample_dataset, 
                            dates, 
                            enumid)
kable(head(reportlog,10))
```

### Number of surveys per day by enumerator

```{r eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}
reportlog <- chk6c_nb_survey(sample_dataset, 
                             surveydte, 
                             enumid)
kable(head(reportlog,10))
```

### Surveyors with productivity significantly different from the average (low or high)

```{r eval=TRUE, echo=TRUE, results='asis'}

reportlog <- chk6f_productivity(sample_dataset, 
                                enumid, 
                                surveydte, 
                                sdvalue)
kable(head(reportlog,10))
```


